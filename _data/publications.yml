- title: "A Study of Deep Single Sketch-Based Modeling: View/Style Invariance, Sparsity and Latent Space Disentanglement"
  authors: "Yue Zhong, <b>Yulia Gryaditskaya</b>, Honggang Zhang, Yi-Zhe Song"
  venue: "A preprint article"
  year: 2022  
  paper_link: "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3999114"
  preview_img_link: "./Papers/22_SBM_journal/preview.png"
  img_width: '130px'
  bibtex_link: "./Papers/22_SBM_journal/22_SBM_journal.bib"
  abstract: "Deep image-based modeling has received a lot of attention in recent years. Sketch-based modeling in particular has gained popularity given the ubiquitous nature of touchscreen devices. In this paper, we (i) study and compare diverse single-image reconstruction methods on sketch input, comparing the different 3D shape representations: multi-view, voxel- and point-cloud-based, mesh-based and implicit ones; and (ii) analyze the main challenges and requirements of sketch-based modeling systems. We introduce the regression loss and provide two variants of its formulation for the two most promising 3D shape representations: point clouds and signed distance functions. We show that this loss can increase general reconstruction accuracy, and the view- and style-robustness of the reconstruction methods. Moreover, we demonstrate that this loss can benefit the disentanglement of latent space to view-invariant and view-specific information, resulting in further improved performance. To address the figure-ground ambiguity typical for sparse human sketches, we propose a two-branch architecture that exploits sparse user labeling. We hope that our work will inform future research on sketch-based modeling. We will release our datasets and their splits to establish the first benchmark in sketch- based modeling."
  publ_id: "2022_1"
  type: "p"

- title: "One Sketch for All: One-Shot Personalized Sketch Segmentation"
  authors: "Anran Qi, <b>Yulia Gryaditskaya</b>, Tao Xiang, Yi-Zhe Song"
  venue: "A preprint article: arXiv:2112.10838"
  year: 2021  
  paper_link: "https://arxiv.org/abs/2112.10838"
  preview_img_link: "./Papers/22_Sketch_Segmentation/preview.png"
  img_width: '130px'
  bibtex_link: "./Papers/22_Sketch_Segmentation/qi2021OneSketch4All.bib"
  abstract: "We present the first one-shot personalized sketch segmentation method. We aim to segment all sketches belonging to the same category provisioned with a single sketch with a given part annotation while (i) preserving the parts semantics embedded in the exemplar, and (ii) being robust to input style and abstraction. We refer to this scenario as personalized. With that, we importantly enable a much-desired personalization capability for downstream fine-grained sketch analysis tasks. To train a robust segmentation module, we deform the exemplar sketch to each of the available sketches of the same category. Our method generalizes to sketches not observed during training. Our central contribution is a sketch-specific hierarchical deformation network. Given a multi-level sketch-strokes encoding obtained via a graph convolutional network, our method estimates rigid-body transformation from the reference to the exemplar, on the upper level. Finer deformation from the exemplar to the globally warped reference sketch is further obtained through stroke-wise deformations, on the lower level. Both levels of deformation are guided by mean squared distances between the keypoints learned without supervision, ensuring that the stroke semantics are preserved. We evaluate our method against the state-of-the-art segmentation and perceptual grouping baselines re-purposed for the one-shot setting and against two few-shot 3D shape segmentation methods. We show that our method outperforms all the alternatives by more than 10% on average. Ablation studies further demonstrate that our method is robust to personalization: changes in input part semantics and style differences."
  publ_id: "2021_3"
  type: "p"
  
- title: "Fine-Grained VR Sketching: Dataset and Insights"
  title_link: ""
  authors: "Ling Luo, <b>Yulia Gryaditskaya</b>, Yongxin Yang, Tao Xiang, Yi-Zhe Song"
  venue: "Proceedings of International Conference on 3D Vision (3DV)"
  year: 2021  
  paper_link: "https://www.computer.org/csdl/proceedings-article/3dv/2021/268800b003/1zWE3NZ5Apq"
  preview_img_link: "./Papers/3DV_21/preview.PNG"
  img_width: '160px'  
  project_link: "https://tinyurl.com/VRSketch3DV21"
  bibtex_link: "./Papers/3DV_21/luo2021FineGrainedVR.bib"  
  publ_id: "2021_2"
  type: "c"
  
- title: "Towards Fine-Grained Sketch-Based 3D Shape Retrieval"
  title_link: ""
  authors: "Anran Qi, <b>Yulia Gryaditskaya</b>, Jifei Song, Yongxin Yang, Yonggang Qi, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song"
  venue: "IEEE Transactions on Image Processing"
  year: 2021  
  paper_link: "https://ieeexplore.ieee.org/document/9573376?source=authoralert"
  preview_img_link: "./Papers/TIP_Retrieval/preview.png"
  img_width: '130px'
  bibtex_link: "./Papers/TIP_Retrieval/qi2021Retrieval.bib"
  abstract: "In this paper we study, for the first time, the problem1of fine-grained sketch-based 3D shape retrieval. We advocate the use  of  sketches  as  a  fine-grained  input  modality  to  retrieve  3D shapes  at  instance-level
  –  e.g.,  given  a  sketch  of  a  chair,  we  set out to retrieve a specific chair from a gallery of all chairs. 
  Fine-grained sketch-based 3D shape retrieval (FG-SBSR) has not been possible till now due to a lack of datasets that exhibit one-to-one 
  sketch-3D  correspondences.  The  first  key  contribution  of  this 
  paper  is  two  new  datasets,  consisting  a  total  of  4,680  sketch-3D  
  pairings  from  two  object  categories.  Even  with  the  datasets, 
  FG-SBSR  is  still  highly  challenging  because  (i)  the  inherent 
  domain  gap  between  2D  sketch  and  3D  shape  is  large,  and  
  (ii) retrieval  needs  to  be  conducted  at  the  instance  level  instead  of 
  the coarse category level matching as in traditional SBSR. 
  Thus, the  second  contribution  of  the  paper  is  the  first  cross-modal deep  
  embedding  model  for  FG-SBSR,  which  specifically  tackles the  unique  challenges  
  presented  by  this  new  problem.  Core  to the deep embedding model is a novel cross-modal view attention 
  module  which  automatically  computes  the  optimal  combination
  of  2D  projections  of  a  3D  shape  given  a  query  sketch."
  publ_id: "2021_1"
  type: "j"
  

  

- title: "Towards Practical Sketch-based 3D Shape Generation: The Role of Professional Sketches"
  title_link: ""
  authors: "Yue Zhong, Yonggang Qi, <b>Yulia Gryaditskaya</b>, Honggang Zhang, Yi-Zhe Song"
  venue: "IEEE Transactions on Circuits and Systems for Video Technology"
  year: 2020  
  paper_link: "https://openresearch.surrey.ac.uk/esploro/outputs/journalArticle/Towards-Practical-Sketch-based-3D-Shape-Generation/99526523602346"
  preview_img_link: "./Papers/ProSketch/preview.png"
  img_width: '130px'
  bibtex_link: "./Papers/ProSketch/zhong2020towards.bib"
  abstract: "In this paper, for the first time, we investigate the problem of generating 3D shapes from professional 2D sketches via deep learning. We target sketches done by professional artists, as these sketches are likely to contain more details than the ones produced by novices, and thus the reconstruction from such sketches poses a higher demand on the level of detail in the reconstructed models. This is importantly different to previous work, where the training and testing was conducted on either synthetic sketches or sketches done by novices. Novices sketches often depict shapes that are physically unrealistic, while models trained with synthetic sketches could not cope with the level of abstraction and style found in real sketches. To address this problem, we collected the first large-scale dataset of professional sketches, where each sketch is paired with a reference 3D shape, with a total of 1,500 professional sketches collected across 500 3D shapes. The dataset is available at http://sketchx.ai/downloads/. We introduce two bespoke designs within a deep adversarial network to tackle the imprecision of human sketches and the unique figure/ground ambiguity problem inherent to sketch-based reconstruction. We show that existing 3D shapes generation methods designed for images fail to be naively applied to our problem, and demonstrate the effectiveness of our method both qualitatively and quantitatively."
  publ_id: "2020_1"
  type: "j"
  
- title: "Towards 3D VR-Sketch to 3D Shape Retrieval"
  title_link: "https://tinyurl.com/3DSketch3DV"
  authors: "Ling Luo, <b>Yulia Gryaditskaya</b>, Yongxin Yang, Tao Xiang, Yi-Zhe Song"
  venue: "Proceedings of International Conference on 3D Vision (3DV) - (Oral)"
  year: 2020  
  paper_link: "https://rowl1ng.com/assets/pdf/3DV_VRSketch.pdf"
  preview_img_link: "./Papers/3DV/Sketch3D/preview.png"
  img_width: '110px'  
  project_link: "https://tinyurl.com/3DSketch3DV"
  bibtex_link: "./Papers/3DV/Sketch3D/luo2020towards.bib"  
  publ_id: "2020_2"
  type: "c"
  
- title: "Deep Sketch-Based Modeling: Tips and Tricks"
  preview_img_link: "./Papers/3DV/DeepSketch/preview.png"
  img_width: '110px'  
  title_link: "https://tinyurl.com/DeepSketchModeling"
  authors: "Yue Zhong, <b>Yulia Gryaditskaya</b>, Honggang Zhang, Yi-Zhe Song"
  venue: "Proceedings of International Conference on 3D Vision (3DV) - (Spotlight)"
  year: 2020  
  paper_link: "https://arxiv.org/pdf/2011.06133.pdf"
  project_link: "https://tinyurl.com/DeepSketchModeling"
  bibtex_link: "./Papers/3DV/DeepSketch/zhong2020deep.bib"
  publ_id: "2020_3"
  type: "c"
  
- title: "Lifting Freehand Concept Sketches into 3D"
  preview_img_link: "./Papers/Lift3D/preview.png"
  img_width: '110px'  
  title_link: "https://ns.inria.fr/d3/Lift3D"
  authors: "<b>Yulia Gryaditskaya</b>, Felix Hähnlein, <a href='https://www.cs.ubc.ca/~chenxil/'>Chenxi Liu</a>, <a href='https://www.cs.ubc.ca/~sheffa/'>Alla Sheffer</a>, <a href='http://www-sop.inria.fr/members/Adrien.Bousseau/'>Adrien Bousseau</a>"
  venue: "ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)"
  year: 2020  
  paper_link: "https://repo-sam.inria.fr/d3/Lift3D/Gryaditskaya_SigAsia20_Lifting%20_Freehand_Concept_Sketches_into_3D.pdf"
  project_link: "https://ns.inria.fr/d3/Lift3D"
  bibtex_link: "./Papers/Lift3D/gryaditskaya2020lifting.bib"
  publ_id: "2020_5"
  type: "j"
  
- title: "Pixelor: A Competitive Sketching AI Agent. So you think you can beat me?"
  preview_img_link: "./Papers/Pixelor/preview.jpg"
  img_width: '110px'  
  title_link: "http://sketchx.ai/pixelor"
  authors: "Ayan Kumar Bhunia, Ayan Das, Umar Riaz Muhammad, Yongxin Yang, Timothy Hospedales, Tao Xiang, <b>Yulia Gryaditskaya</b>, Yi-Zhe Song"
  venue: "ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)"
  year: 2020  
  paper_link: "https://dl.acm.org/doi/pdf/10.1145/3414685.3417840"
  project_link: "http://sketchx.ai/pixelor"
  bibtex_link: "./Papers/Pixelor/bhunia2020pixelor.bib"
  publ_id: "2020_4"
  type: "j"
  
  
- title: "OpenSketch: A Richly-Annotated Dataset of Product Design Sketches"
  preview_img_link: "./Papers/OpenSketch/preview_open_sketch.png"
  img_width: '110px'  
  title_link: "https://ns.inria.fr/d3/OpenSketch/"
  authors: "<b>Yulia Gryaditskaya</b>, <a href='https://www.marksypesteyn.com/'>Mark Sypesteyn</a>, <a href='https://www.linkedin.com/in/janwillemhoftijzer'>Jan Willem Hoftijzer</a>, <a href='https://www.tudelft.nl/en/ide/about-ide/personal-profiles/professors/pont-sc/'>Sylvia Pont</a>, <a href='http://people.csail.mit.edu/fredo/'>Fr&eacute;do Durand</a>, <a href='http://www-sop.inria.fr/members/Adrien.Bousseau/'>Adrien Bousseau</a>"
  venue: "ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)"
  year: 2019  
  paper_link: "https://repo-sam.inria.fr/d3/OpenSketch/Gryaditskaya_OpenSketch_AuthorsVersion.pdf"
  project_link: "https://ns.inria.fr/d3/OpenSketch/"
  bibtex_link: "./Papers/OpenSketch/gryaditskaya2019opensketch.bib"
  publ_id: "2019_2"
  type: "j"
  
- title: "Bitmap or Vector? A study on sketch representations for deep stroke segmentation"
  preview_img_link: "./Papers/BitmapVector/preview.png"
  img_width: '110px'  
  title_link: "https://hal.inria.fr/hal-02922043/"
  authors: "Felix Hähnlein, <a href='http://yulia.gryaditskaya.com/'><b>Yulia Gryaditskaya</b></a>, <a href='http://www-sop.inria.fr/members/Adrien.Bousseau/'>Adrien Bousseau</a>"
  venue: "Journées Francaises d'Informatique Graphique et de Réalité virtuelle"
  year: 2019  
  paper_link: "https://hal.inria.fr/hal-02922043/document"
  project_link: ""
  bibtex_link: "./Papers/BitmapVectorhahnlein2019bitmap.bib"
  publ_id: "2019_1"
  type: "c"

- title: "High Dynamic Range Imaging: Problems of Video Exposure Bracketing, Luminance Calibration and Gloss Editing"
  preview_img_link: "./Thesis/preview.png"
  img_width: '110px'  
  title_link: "https://diglib.eg.org/handle/10.2312/2631883"
  authors: "<b>Yulia Gryaditskaya</b>"
  venue: "PhD Thesis, Faculty of Mathematics and Computer Science of Saarland University"
  year: 2017  
  paper_link: "https://diglib.eg.org/bitstream/handle/10.2312/2631883/thesis_gryaditskaya_compressed.pdf?sequence=1&isAllowed=y"
  project_link: ""
  bibtex_link: "./Thesis/gryaditskaya2017thesis.bib"
  publ_id: "2017_1"
  type: "d"
  
- title: "Gloss Editing in Light Fields"
  preview_img_link: "Papers/GlossEditing/preview.png"
  img_width: '110px'  
  title_link: "Papers/GlossEditing/index.html#vmv1"
  authors: "<a href='http://yulia.gryaditskaya.com/'><b>Yulia Gryaditskaya</b></a>, <a href='http://webdiis.unizar.es/~bmasia/'>Belen Masia</a>, <a href='https://www.pdf.inf.usi.ch/people/piotr/'>Piotr Didyk</a>, <a href='https://people.mpi-inf.mpg.de/~karol/'>Karol Myszkowski</a>,<a href='https://people.mpi-inf.mpg.de/~hpseidel/'>Hans-Peter Seidel</a>"
  venue: " Proceedings of International Workshop on Vision, Modeling and Visualization (VMV)"
  year: 2016  
  paper_link: "Papers/GlossEditing/2016_Gryaditskaya_GlossEditingLF.pdf"
  project_link: "Papers/GlossEditing/index.html#vmv1"
  bibtex_link: "Papers/GlossEditing/gryaditskaya2016gloss.bib"
  publ_id: "2016_1"
  type: "c"

- title: "Motion Aware Exposure Bracketing for HDR Video"
  preview_img_link: "Papers/HDRVideo/preview.png"
  img_width: '110px'  
  title_link: "Papers/HDRVideo/index.html#egsr15"
  authors: " <a href='http://yulia.gryaditskaya.com/'><b>Yulia Gryaditskaya</b></a>, <a href='http://taniapouli.me/'>Foteini Tania Pouli</a>, <a href='hhttp://erikreinhard.com/about.html'>Erik Reinhard</a>, <a href='https://people.mpi-inf.mpg.de/~karol/'>Karol Myszkowski</a>, <a href='https://people.mpi-inf.mpg.de/~hpseidel/'>Hans-Peter Seidel</a>"
  venue: " Computer Graphics Forum (Proc. EGSR)"
  year: 2015  
  paper_link: "Papers/HDRVideo/ExposureBracketingHDRVideo.pdf"
  project_link: "Papers/HDRVideo/index.html#egsr15"
  bibtex_link: "Papers/HDRVideo/gryaditskaya2015motion.bib"
  publ_id: "2015_1"
  type: "j"

- title: "Sky Based Light Metering for High Dynamic Range Images"
  preview_img_link: "Papers/LightMetering/preview.png"
  img_width: '110px'  
  title_link: "Papers/LightMetering/index.html#pg14"
  authors: "<a href='http://yulia.gryaditskaya.com/'><b>Yulia Gryaditskaya</b></a>, <a href='http://taniapouli.me/'>Foteini Tania Pouli</a>, <a href='hhttp://erikreinhard.com/about.html'>Erik Reinhard</a>, <a href='https://people.mpi-inf.mpg.de/~hpseidel/'>Hans-Peter Seidel</a>"
  venue: " Computer Graphics Forum (Proc. Pacific Graphics)"
  year: 2014  
  paper_link: "Papers/LightMetering/LM_Supp.pdf"
  project_link: "Papers/LightMetering/index.html#pg14"
  bibtex_link: "Papers/LightMetering/gryaditskaya2014sky.bib"
  publ_id: "2014_1"  
  type: "j"