---
layout: main
title: 'Datasets'
permalink: /datasets/
---

<!-- Main Content -->
<section  id="datasets">
    <div class="album py-5 bg-light">
        
        <div class="container">		
                <h3> Released datasets </h3>
                            <!-- ---- -->
                <div class='publ_year'> 2024 </div>
                
                <div class="row mt-3 mb-1">
                
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">		
                            <img src='{{ site.baseurl }}/DatasetsThumbs/fscoco-seg.png'  width = '99%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                            <div class="card w-100">	
                            <div class="card-body">
                                <div class = 'title card-title'>
                                    FSCOCO-seg: Annotated scene sketches <a href='http://cvssp.org/data/fscoco-seg'>(Webpage link)</a> 								
                                </div>
                                
                                <div class = 'DatasetDesc card-text' >
                                    It contains our split of the sketches from the <a href="http://cvssp.org/data/fscoco">FSCOCO dataset</a> into training, 
                                    validation and test sets. For the validation and test sets, 
                                    we provide stroke-level annotations into different categories, as shown in the teaser image. 
                                    <br>
                                    This datset is a part of the paper:
                                                        
                                    <div style="color:grey">
                                    Open Vocabulary Scene Sketch Semantic Understanding <br>
                                    Ahmed Bourouis, Judith Ellen Fan, Yulia Gryaditskaya, CVPR, 2024.
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                
                <!-- ---- -->
                <div class='publ_year'> 2022 </div>
                
                <div class="row mt-3 mb-1">
                
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">		
                            <img src='{{ site.baseurl }}/Papers/22_ECCV/thumb.png'  width = '99%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                            <div class="card w-100">	
                            <div class="card-body">
                                <div class = 'title card-title'>
                                    <a href='http://cvssp.org/data/fscoco'>FS-COCO: Scene sketches</a> <br>
                                    <a href='http://cvssp.org/data/fscoco/fscoco.tar.gz'>fscoco.tar.gz (2.2 GB)</a>
                                </div>
                                
                                <div class = 'DatasetDesc card-text' >
                                    Our dataset	comprises 10, 000 freehand scene vector sketches with per point space-time information by 100 non-expert individuals, offering both object-and scene-level abstraction. Each sketch is augmented with its text description.
                                    
                                    This datset is a part of the paper:
                                                        
                                    <div style="color:grey">
                                    FS-COCO: Towards Understanding of Freehand Sketches of Common Objects in COntext <br>
                                    Pinaki Nath Chowdhury, Aneeshan Sain, Ayan Kumar Bhunia, Tao Xiang, Yulia Gryaditskaya, Yi-Zhe Song <br>
                                    ECCV, 2022.
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- ---- -->
                <div class='publ_year'> 2021 </div>
                
                <div class="row mt-3 mb-1">
                
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">		
                            <img src='{{ site.baseurl }}/DatasetsThumbs/VR21.png'  width = '99%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                            <div class="card w-100">	
                            <div class="card-body">
                                <div class = 'title card-title'>
                                    <a href='https://cvssp.org/data/VRChairSketch/'> 3D VR chair sketches by non professionals </a>
                                </div>
                                
                                <div class = 'DatasetDesc card-text' >
                                    We present the first fine-grained dataset of 1,497 3D VR sketch and 3D shape pairs for 1,005 chair shapes with large shapes diversity from the ShapeNetCore dataset from 50 participants.
                                    
                                    This datset is a part of the paper:
                                                        
                                    <div style="color:grey">
                                    Fine-Grained VR Sketching: Dataset and Insights <br>
                                    Ling Luo, Yulia Gryaditskaya, Yongxin Yang, Tao Xiang, Yi-Zhe Song <br>
                                    Proceedings of International Conference on 3D Vision (3DV), 2021.
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
				
                <div class="row mt-3 mb-1">
                    
                    
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">		
                        <img src='{{ site.baseurl }}/Papers/TIP_Retrieval/preview.png'  width = '88%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                        <div class="card w-100">	
                            <div class="card-body">
                                <div class = 'title card-title'>                                    
                                    <a href='https://drive.google.com/file/d/1At3-FgUZaqjKeUePDxSXXEqtChkSCfn1/view?usp=sharing'> FG-SBSR-Lamps-Chairs </a>
                                </div>
                                
                                <div class = 'DatasetDesc card-text'>
                                    FG-SBSR (Fine-Grained Sketch-based 3D Shape Retrieval) datasets, consisting of a total of 4,680 sketch-3D
									one-to-one pairings across two categories (chair and lamp).
									The dataset is built via crowd-sourcing by asking users to
									finger sketch on a touchscreen device by recollection, after
									observing a model for a fixed amount of time.
									<br>
									<b>Data collection</b>: We first render each shape reference images from three
									distinctive views, those number and viewpoints are selected
									according to sketch literature and our pilot study. Then, we show one reference image
									to a volunteer for 15 seconds, then display a blank canvas
									and let the volunteer sketch the object that he/she just saw
									from memory using fingers on a tablet/phone. 30 volunteers
									are recruited to sketch the reference images. Volunteers did not
									have any art training and thus represent the general population
									who might use the fine-grained SBSR system. 
									<br>
									<b>Data filtering</b>: First, each reference image is sketched by two different volunteers. After
									finishing collecting all sketches, for quality control purposes,
									three additional volunteers vote to select the best sketch out
									of the two, for each reference image.
									
									<br>
                                    Please cite the follwoing work, if you are using this dataset:
                                                        
                                    <div style="color:grey">
                                    Toward fine-grained sketch-based 3D shape retrieval <br>
                                    Anran Qi, Yulia Gryaditskaya, Jifei Song, Yongxin Yang, Yonggang Qi, Timothy M Hospedales, Tao Xiang, Yi-Zhe Song <br>
                                    IEEE Transactions on Image Processing, 2021.
                                    </div>
                                    
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                
                <!-- ---- -->
                <div class='publ_year'> 2020 </div>
                
                <div class="row mt-3 mb-1">
                
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">		
                            <img src='{{ site.baseurl }}/DatasetsThumbs/SlowSketch.png'  width = '99%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                            <div class="card w-100">	
                            <div class="card-body">
                                <div class = 'title card-title'>
                                    <a href='https://drive.google.com/file/d/1mWEY7vFkOw790DwUtqcTX8fHzNBP_b1J/view?usp=sharing'> SlowSketch </a>
                                </div>
                                
                                <div class = 'DatasetDesc card-text' >
                                    1700 sketches from 12 participants of 20 categories, where the participants were asked to target early sketch recognition.
                                    
                                    This datset is a part of the paper:
                                                        
                                    <div style="color:grey">
                                    Pixelor: A Competitive Sketching AI Agent. So you think you can sketch? <br>
                                    Ayan Kumar Bhunia, Ayan Das, Umar Riaz Muhammad, Yongxin Yang, Timothy Hospedales, Tao Xiang, Yulia Gryaditskaya, Yi-Zhe Song <br>
                                    ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia), 2020.
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- ---- -->
                <!-- <div class='publ_year'> 2020 </div> -->
                <div class="row mt-3 mb-1">
                    
                    
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">		
                        <img src='{{ site.baseurl }}/DatasetsThumbs/ProSketch-3DChair.jpg'  width = '88%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                        <div class="card w-100">	
                            <div class="card-body">
                                <div class = 'title card-title'>
                                     <!-- <a href='http://personal.ee.surrey.ac.uk/Personal/Y.Song/ProSketch-3Dchair.zip'> ProSketch-3DChair </a> -->
                                    <a href='https://drive.google.com/file/d/1lcGzenXmoaynl-lKlewZrU_4T9KipaGr/view?usp=sharing'> ProSketch-3DChair </a>
                                </div>
                                
                                <div class = 'DatasetDesc card-text'>
                                    A dataset of 1500 chair sketches by professional artists: front, side and 3/4 viewpoints.
                                    
                                    This datset is a part of the paper:
                                                        
                                    <div style="color:grey">
                                    Towards Practical Sketch-based 3D ShapeGeneration: The Role of Professional Sketches <br>
                                    Yue Zhong, Yonggang Qi, Yulia Gryaditskaya, Honggang Zhang, Yi-Zhe Song <br>
                                    IEEE Transactions on Circuits and Systems for Video Technology, 2020.
                                    </div>
                                    
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- ---- -->
                <!-- <div class='publ_year'> 2020 </div> -->
                <div class="row mt-3 mb-1">
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">	
                        <img src='{{ site.baseurl }}/DatasetsThumbs/SChairSketch.png'  width = '99%'  />
                        </div>
                    </div>
                    
                        <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                        <div class="card w-100">
                        <div class="card-body">
                            <div class = 'title card-title'>
                                <a href='https://cvssp.org/data/SyntheticChairSketch/'> Synthetic Chair Sketches </a>
                            </div>
                            
                            <div class = 'DatasetDesc card-text'>
                                The datset contains NPR sketches for a chair category of the ShapeNetCore dataset in two styles. 
                                This datset is a part of the paper:
                                
                                <div style="color:grey">
                                Deep Sketch-Based Modeling: Tips and Tricks <br>
                                Yue Zhong, Yulia Gryaditskaya, Honggang Zhang, Yi-Zhe Song <br>
                                Proceedings of International Conference on 3D Vision (3DV) - (Spotlight), 2020.
                                </div>
                            </div>
                        </div>
                        </div>
                    </div>
                </div>
                
                
      
                
                <!-- ---- -->
                
                <!-- <div class='publ_year'> 2020 </div> -->
                <div class="row mt-3 mb-1">
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">	
                        <img src='{{ site.baseurl }}/DatasetsThumbs/Bathtubs-Chairs.png'  width = '99%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                        <div class="card w-100">
                        <div class="card-body">
                            <div class = 'title card-title'>
                            <a href='https://drive.google.com/file/d/1FkKZfWt7O4xMy4ir5kCYcmwZLPk1uBcZ/view?usp=sharing'>3D VR sketch-3D Shape pairs</a>
                            </div>
                        
                            <div class = 'DatasetDesc card-text'>
                                139 chair and 28 bathtub 3D VR sketches by novices.
                                This datset is a part of the paper:
                                                        
                                    <div style="color:grey">
                                    Towards 3D VR-Sketch to 3D Shape Retrieval <br>
                                    Ling Luo, Yulia Gryaditskaya, Yongxin Yang, Tao Xiang, Yi-Zhe Song <br>
                                    Proceedings of International Conference on 3D Vision (3DV) - (Oral), 2020.
                                    </div>
                            </div>
                        </div>
                        </div>
                    </div>
                </div>
                
                <!-- ---- -->
                
                <!-- <div class='publ_year'> 2020 </div> -->
                <div class="row mt-3 mb-1">
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">	
                        <img src='{{ site.baseurl }}/DatasetsThumbs/OpenSketch++.png'  width = '99%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                        <div class="card w-100">
                        <div class="card-body">
                            <div class = 'title card-title'>
                                <a href='https://repo-sam.inria.fr/d3/Lift3D/OpenSketch++.zip'>OpenSketch++</a>
                            </div>
                            
                            <div class = 'DatasetDesc'>
                                16 Vector concept sketches by 2 designers, collected in addtion to the skecthes in the OpenSketch dataset.
                                This datset is a part of the paper:
                                                        
                                    <div style="color:grey">
                                    
                                    Lifting Freehand Concept Sketches into 3D <br>
                                    Yulia Gryaditskaya, Felix Hähnlein, Chenxi Liu, Alla Sheffer, Adrien Bousseau <br>
                                    ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia), 2020.
                                    </div>
                            </div>
                        </div>
                        </div>
                    </div>
                </div>
                
                <!-- ---- -->
                
                <div class='publ_year'> 2019 </div>
                
                <div class="row mt-3 mb-1">
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">	
                        <img src='{{ site.baseurl }}/DatasetsThumbs/OpenSketch.png'  width = '99%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                        <div class="card w-100">
                            <div class="card-body">
                                <div class = 'title card-title'>
                                    <a href='https://repo-sam.inria.fr/d3/OpenSketch/'>OpenSketch</a>
                                </div>
                                
                                <div class = 'DatasetDesc'>
                                    A richly-annotated dataset of more than 400 product design sketches.
                                    This datset is a part of the paper:
                                                        
                                    <div style="color:grey">
                                    
                                    OpenSketch: A Richly-Annotated Dataset of Product Design Sketches <br>
                                    Yulia Gryaditskaya, Mark Sypesteyn, Jan Willem Hoftijzer, Sylvia Pont, Frédo Durand, Adrien Bousseau <br>
                                    ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia), 2019.
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                    
                <div class='publ_year'> 2014 </div>
                
                <div class="row mt-3 mb-1">
                    <div class="col-sm-3 align-items-stretch d-flex align-items-stretch">
                        <div class="card align-items-center justify-content-center w-100">	
                        <img src='{{ site.baseurl }}/DatasetsThumbs/HDR.png'  width = '99%'  />
                        </div>
                    </div>
                    
                    <div class="col-sm-9 align-items-stretch d-flex align-items-stretch">
                        <div class="card w-100">
                            <div class="card-body">
                                <div class = 'title card-title'>
                                    <a href='https://drive.google.com/file/d/12qovT3CuJIVHVdM2wtA4RXi62-4sVoDO/view?usp=sharing'>Calibrated HDR Images</a>
                                </div>
                                
                                <div class = 'DatasetDesc'>
                                    A set of calibrated HDR images, with visible sky regions and color checker.
                                    
                                    This datset is a part of the paper:
                                                        
                                    <div style="color:grey">
                                        Sky Based Light Metering for High Dynamic Range Images <br>
                                        Yulia Gryaditskaya, Foteini Tania Pouli, Erik Reinhard, Hans-Peter Seidel <br>
                                        Computer Graphics Forum (Proc. Pacific Graphics), 2014.
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                
        </div>	
    </div>	
    </section>       	
            


<!-- Footer (optional) -->
<footer class="footer bg-light text-center">
    <div class="container">
        <span class="text-muted">&copy; 2024 Yulia Gryaditskaya</span>
    </div>
</footer>

<!-- Scripts (optional) -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.bundle.min.js"></script>
